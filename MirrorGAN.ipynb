{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MirrorGAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVjxLWfuoDwS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlcYXI34T5bU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content')\n",
        "!rm -r MirrorGAN\n",
        "!git clone https://github.com/qiaott/MirrorGAN.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7SU-8OEUQ7u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content') \n",
        "os.mkdir('data')\n",
        "os.chdir('/content/data') \n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1CuW5ognTSkNbyx9TWoUFrgwqxZNk1cl0' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1CuW5ognTSkNbyx9TWoUFrgwqxZNk1cl0\" -O data.zip && rm -rf /tmp/cookies.txt\n",
        "!unzip -q data.zip\n",
        "!rm data.zip\n",
        "!rm -r __MACOSX/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXBw8LmyxErC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content')\n",
        "!git clone https://github.com/ammarnasr/CUB-Attn-GAN.git\n",
        "\n",
        "os.chdir('/content/data') \n",
        "!rm -r STEM/\n",
        "os.mkdir('STEM')\n",
        "os.chdir('/content/data/STEM')\n",
        "\n",
        "!mv /content/CUB-Attn-GAN/theModel/text_encoder599.pth /content/data/STEM/\n",
        "!mv /content/CUB-Attn-GAN/theModel/image_encoder599.pth /content/data/STEM/\n",
        "\n",
        "!mv text_encoder599.pth text_encoder.pth\n",
        "!mv image_encoder599.pth image_encoder.pth\n",
        "\n",
        "!rm -r /content/CUB-Attn-GAN/\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRkiFyx1qkD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/data') \n",
        "!rm -r STREAM/\n",
        "os.mkdir('STREAM')\n",
        "os.chdir('/content/data/STREAM')\n",
        "\n",
        "!wget https://www.dropbox.com/s/ne0ixz5d58ccbbz/pretrained_model.zip\n",
        "!unzip -q pretrained_model.zip\n",
        "!rm pretrained_model.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Me0BOJrfZHrG",
        "colab_type": "text"
      },
      "source": [
        "# ======================================================================="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YybaFtWtuXsT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "outputId": "f5b006c6-d9dd-48de-a8c3-36258803297b"
      },
      "source": [
        "os.chdir('/content')\n",
        "!rm -r mirrorGAN\n",
        "!git clone https://github.com/ammarnasr/mirrorGAN.git\n",
        "\n",
        "!rm /content/mirrorGAN/README.md\n",
        "!rm /content/mirrorGAN/MirrorGAN.ipynb\n",
        "!rm /content/mirrorGAN/do_train.sh\n",
        "\n",
        "!mv /content/mirrorGAN/config.py /content/MirrorGAN/cfg/\n",
        "!mv /content/mirrorGAN/train_bird.yml /content/MirrorGAN/cfg/\n",
        "\n",
        "!mv /content/mirrorGAN/datasets.py /content/MirrorGAN/\n",
        "!mv /content/mirrorGAN/model.py /content/MirrorGAN/\n",
        "!mv /content/mirrorGAN/trainer.py /content/MirrorGAN/\n",
        "!mv /content/mirrorGAN/main.py /content/MirrorGAN/\n",
        "\n",
        "!mv /content/mirrorGAN/attn_captions.pickle /content/data/birds/"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'mirrorGAN'...\n",
            "remote: Enumerating objects: 76, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/76)\u001b[K\rremote: Counting objects:   2% (2/76)\u001b[K\rremote: Counting objects:   3% (3/76)\u001b[K\rremote: Counting objects:   5% (4/76)\u001b[K\rremote: Counting objects:   6% (5/76)\u001b[K\rremote: Counting objects:   7% (6/76)\u001b[K\rremote: Counting objects:   9% (7/76)\u001b[K\rremote: Counting objects:  10% (8/76)\u001b[K\rremote: Counting objects:  11% (9/76)\u001b[K\rremote: Counting objects:  13% (10/76)\u001b[K\rremote: Counting objects:  14% (11/76)\u001b[K\rremote: Counting objects:  15% (12/76)\u001b[K\rremote: Counting objects:  17% (13/76)\u001b[K\rremote: Counting objects:  18% (14/76)\u001b[K\rremote: Counting objects:  19% (15/76)\u001b[K\rremote: Counting objects:  21% (16/76)\u001b[K\rremote: Counting objects:  22% (17/76)\u001b[K\rremote: Counting objects:  23% (18/76)\u001b[K\rremote: Counting objects:  25% (19/76)\u001b[K\rremote: Counting objects:  26% (20/76)\u001b[K\rremote: Counting objects:  27% (21/76)\u001b[K\rremote: Counting objects:  28% (22/76)\u001b[K\rremote: Counting objects:  30% (23/76)\u001b[K\rremote: Counting objects:  31% (24/76)\u001b[K\rremote: Counting objects:  32% (25/76)\u001b[K\rremote: Counting objects:  34% (26/76)\u001b[K\rremote: Counting objects:  35% (27/76)\u001b[K\rremote: Counting objects:  36% (28/76)\u001b[K\rremote: Counting objects:  38% (29/76)\u001b[K\rremote: Counting objects:  39% (30/76)\u001b[K\rremote: Counting objects:  40% (31/76)\u001b[K\rremote: Counting objects:  42% (32/76)\u001b[K\rremote: Counting objects:  43% (33/76)\u001b[K\rremote: Counting objects:  44% (34/76)\u001b[K\rremote: Counting objects:  46% (35/76)\u001b[K\rremote: Counting objects:  47% (36/76)\u001b[K\rremote: Counting objects:  48% (37/76)\u001b[K\rremote: Counting objects:  50% (38/76)\u001b[K\rremote: Counting objects:  51% (39/76)\u001b[K\rremote: Counting objects:  52% (40/76)\u001b[K\rremote: Counting objects:  53% (41/76)\u001b[K\rremote: Counting objects:  55% (42/76)\u001b[K\rremote: Counting objects:  56% (43/76)\u001b[K\rremote: Counting objects:  57% (44/76)\u001b[K\rremote: Counting objects:  59% (45/76)\u001b[K\rremote: Counting objects:  60% (46/76)\u001b[K\rremote: Counting objects:  61% (47/76)\u001b[K\rremote: Counting objects:  63% (48/76)\u001b[K\rremote: Counting objects:  64% (49/76)\u001b[K\rremote: Counting objects:  65% (50/76)\u001b[K\rremote: Counting objects:  67% (51/76)\u001b[K\rremote: Counting objects:  68% (52/76)\u001b[K\rremote: Counting objects:  69% (53/76)\u001b[K\rremote: Counting objects:  71% (54/76)\u001b[K\rremote: Counting objects:  72% (55/76)\u001b[K\rremote: Counting objects:  73% (56/76)\u001b[K\rremote: Counting objects:  75% (57/76)\u001b[K\rremote: Counting objects:  76% (58/76)\u001b[K\rremote: Counting objects:  77% (59/76)\u001b[K\rremote: Counting objects:  78% (60/76)\u001b[K\rremote: Counting objects:  80% (61/76)\u001b[K\rremote: Counting objects:  81% (62/76)\u001b[K\rremote: Counting objects:  82% (63/76)\u001b[K\rremote: Counting objects:  84% (64/76)\u001b[K\rremote: Counting objects:  85% (65/76)\u001b[K\rremote: Counting objects:  86% (66/76)\u001b[K\rremote: Counting objects:  88% (67/76)\u001b[K\rremote: Counting objects:  89% (68/76)\u001b[K\rremote: Counting objects:  90% (69/76)\u001b[K\rremote: Counting objects:  92% (70/76)\u001b[K\rremote: Counting objects:  93% (71/76)\u001b[K\rremote: Counting objects:  94% (72/76)\u001b[K\rremote: Counting objects:  96% (73/76)\u001b[K\rremote: Counting objects:  97% (74/76)\u001b[K\rremote: Counting objects:  98% (75/76)\u001b[K\rremote: Counting objects: 100% (76/76)\u001b[K\rremote: Counting objects: 100% (76/76), done.\u001b[K\n",
            "remote: Compressing objects:   1% (1/55)\u001b[K\rremote: Compressing objects:   3% (2/55)\u001b[K\rremote: Compressing objects:   5% (3/55)\u001b[K\rremote: Compressing objects:   7% (4/55)\u001b[K\rremote: Compressing objects:   9% (5/55)\u001b[K\rremote: Compressing objects:  10% (6/55)\u001b[K\rremote: Compressing objects:  12% (7/55)\u001b[K\rremote: Compressing objects:  14% (8/55)\u001b[K\rremote: Compressing objects:  16% (9/55)\u001b[K\rremote: Compressing objects:  18% (10/55)\u001b[K\rremote: Compressing objects:  20% (11/55)\u001b[K\rremote: Compressing objects:  21% (12/55)\u001b[K\rremote: Compressing objects:  23% (13/55)\u001b[K\rremote: Compressing objects:  25% (14/55)\u001b[K\rremote: Compressing objects:  27% (15/55)\u001b[K\rremote: Compressing objects:  29% (16/55)\u001b[K\rremote: Compressing objects:  30% (17/55)\u001b[K\rremote: Compressing objects:  32% (18/55)\u001b[K\rremote: Compressing objects:  34% (19/55)\u001b[K\rremote: Compressing objects:  36% (20/55)\u001b[K\rremote: Compressing objects:  38% (21/55)\u001b[K\rremote: Compressing objects:  40% (22/55)\u001b[K\rremote: Compressing objects:  41% (23/55)\u001b[K\rremote: Compressing objects:  43% (24/55)\u001b[K\rremote: Compressing objects:  45% (25/55)\u001b[K\rremote: Compressing objects:  47% (26/55)\u001b[K\rremote: Compressing objects:  49% (27/55)\u001b[K\rremote: Compressing objects:  50% (28/55)\u001b[K\rremote: Compressing objects:  52% (29/55)\u001b[K\rremote: Compressing objects:  54% (30/55)\u001b[K\rremote: Compressing objects:  56% (31/55)\u001b[K\rremote: Compressing objects:  58% (32/55)\u001b[K\rremote: Compressing objects:  60% (33/55)\u001b[K\rremote: Compressing objects:  61% (34/55)\u001b[K\rremote: Compressing objects:  63% (35/55)\u001b[K\rremote: Compressing objects:  65% (36/55)\u001b[K\rremote: Compressing objects:  67% (37/55)\u001b[K\rremote: Compressing objects:  69% (38/55)\u001b[K\rremote: Compressing objects:  70% (39/55)\u001b[K\rremote: Compressing objects:  72% (40/55)\u001b[K\rremote: Compressing objects:  74% (41/55)\u001b[K\rremote: Compressing objects:  76% (42/55)\u001b[K\rremote: Compressing objects:  78% (43/55)\u001b[K\rremote: Compressing objects:  80% (44/55)\u001b[K\rremote: Compressing objects:  81% (45/55)\u001b[K\rremote: Compressing objects:  83% (46/55)\u001b[K\rremote: Compressing objects:  85% (47/55)\u001b[K\rremote: Compressing objects:  87% (48/55)\u001b[K\rremote: Compressing objects:  89% (49/55)\u001b[K\rremote: Compressing objects:  90% (50/55)\u001b[K\rremote: Compressing objects:  92% (51/55)\u001b[K\rremote: Compressing objects:  94% (52/55)\u001b[K\rremote: Compressing objects:  96% (53/55)\u001b[K\rremote: Compressing objects:  98% (54/55)\u001b[K\rremote: Compressing objects: 100% (55/55)\u001b[K\rremote: Compressing objects: 100% (55/55), done.\u001b[K\n",
            "remote: Total 76 (delta 36), reused 54 (delta 17), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (76/76), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8mG_vcAqTKr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "177c7950-7cd4-40f8-97fe-c11ddff89336"
      },
      "source": [
        "os.chdir('/content/MirrorGAN') \n",
        "! ./do_train.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using config:\n",
            "{'B_VALIDATION': False,\n",
            " 'CAP': {'caption_cnn_path': '../data/STREAM/encoder-5-3000.pkl',\n",
            "         'caption_rnn_path': '../data/STREAM/decoder-5-3000.pkl',\n",
            "         'embed_size': 256,\n",
            "         'hidden_size': 256,\n",
            "         'learning_rate': 0.001,\n",
            "         'num_layers': 1},\n",
            " 'CONFIG_NAME': 'MirrorGAN',\n",
            " 'CUDA': True,\n",
            " 'DATASET_NAME': 'birds',\n",
            " 'DATA_DIR': '../data/birds',\n",
            " 'GAN': {'B_ATTENTION': True,\n",
            "         'B_DCGAN': False,\n",
            "         'CONDITION_DIM': 100,\n",
            "         'DF_DIM': 64,\n",
            "         'GF_DIM': 32,\n",
            "         'R_NUM': 2,\n",
            "         'Z_DIM': 100},\n",
            " 'GPU_ID': 0,\n",
            " 'OUTPUT_PATH': '/data/qtt/MirrorGAN/',\n",
            " 'RNN_TYPE': 'LSTM',\n",
            " 'TEXT': {'CAPTIONS_PER_IMAGE': 10, 'EMBEDDING_DIM': 256, 'WORDS_NUM': 18},\n",
            " 'TRAIN': {'BATCH_SIZE': 12,\n",
            "           'B_NET_D': True,\n",
            "           'DISCRIMINATOR_LR': 0.0002,\n",
            "           'ENCODER_LR': 0.0002,\n",
            "           'FLAG': True,\n",
            "           'GENERATOR_LR': 0.0002,\n",
            "           'MAX_EPOCH': 650,\n",
            "           'NET_E': '../data/STEM/text_encoder.pth',\n",
            "           'NET_G': '',\n",
            "           'RNN_GRAD_CLIP': 0.25,\n",
            "           'SMOOTH': {'GAMMA1': 4.0,\n",
            "                      'GAMMA2': 5.0,\n",
            "                      'GAMMA3': 10.0,\n",
            "                      'LAMBDA': 0.0,\n",
            "                      'LAMBDA1': 10.0},\n",
            "           'SNAPSHOT_INTERVAL': 50},\n",
            " 'TREE': {'BASE_SIZE': 64, 'BRANCH_NUM': 3},\n",
            " 'WORKERS': 4}\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:211: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
            "  \"please use transforms.Resize instead.\")\n",
            "Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg\n",
            "Calling Load text data\n",
            "Load filenames from: ../data/birds/train/filenames.pickle (8855)\n",
            "Load filenames from: ../data/birds/test/filenames.pickle (2933)\n",
            "--------------------Load Text Data--------------------------------------\n",
            "FilePath:  ../data/birds/bird_captions.pickle Does Exist :  False\n",
            "Load from:  ../data/birds/bird_captions.pickle\n",
            "Calling Load Class ID\n",
            "Finished Load Class ID \n",
            "Number of Example: 8855\n",
            "Dataset:  <datasets.TextDataset object at 0x7fece87f26d8>\n",
            "Dataloader:  <torch.utils.data.dataloader.DataLoader object at 0x7fec89fe5908>\n",
            "Trainer:  <class 'trainer.Trainer'>\n",
            "----before----\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdBBXnkQqUQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}