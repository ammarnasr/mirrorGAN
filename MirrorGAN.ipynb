{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MirrorGAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVjxLWfuoDwS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlcYXI34T5bU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content')\n",
        "!rm -r MirrorGAN\n",
        "!git clone https://github.com/qiaott/MirrorGAN.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7SU-8OEUQ7u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content') \n",
        "os.mkdir('data')\n",
        "os.chdir('/content/data') \n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1CuW5ognTSkNbyx9TWoUFrgwqxZNk1cl0' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1CuW5ognTSkNbyx9TWoUFrgwqxZNk1cl0\" -O data.zip && rm -rf /tmp/cookies.txt\n",
        "!unzip -q data.zip\n",
        "!rm data.zip\n",
        "!rm -r __MACOSX/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXBw8LmyxErC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content')\n",
        "!git clone https://github.com/ammarnasr/CUB-Attn-GAN.git\n",
        "\n",
        "os.chdir('/content/data') \n",
        "!rm -r STEM/\n",
        "os.mkdir('STEM')\n",
        "os.chdir('/content/data/STEM')\n",
        "\n",
        "!mv /content/CUB-Attn-GAN/theModel/text_encoder599.pth /content/data/STEM/\n",
        "!mv /content/CUB-Attn-GAN/theModel/image_encoder599.pth /content/data/STEM/\n",
        "\n",
        "!mv text_encoder599.pth text_encoder.pth\n",
        "!mv image_encoder599.pth image_encoder.pth\n",
        "\n",
        "!rm -r /content/CUB-Attn-GAN/\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRkiFyx1qkD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/data') \n",
        "!rm -r STREAM/\n",
        "os.mkdir('STREAM')\n",
        "os.chdir('/content/data/STREAM')\n",
        "\n",
        "!wget https://www.dropbox.com/s/ne0ixz5d58ccbbz/pretrained_model.zip\n",
        "!unzip -q pretrained_model.zip\n",
        "!rm pretrained_model.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Me0BOJrfZHrG",
        "colab_type": "text"
      },
      "source": [
        "# ======================================================================="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YybaFtWtuXsT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "outputId": "9a9a36ee-4369-4723-d565-90d455475315"
      },
      "source": [
        "os.chdir('/content')\n",
        "!rm -r mirrorGAN\n",
        "!git clone https://github.com/ammarnasr/mirrorGAN.git\n",
        "\n",
        "!rm /content/mirrorGAN/README.md\n",
        "!rm /content/mirrorGAN/MirrorGAN.ipynb\n",
        "!rm /content/mirrorGAN/do_train.sh\n",
        "!rm /content/mirrorGAN/main.py\n",
        "\n",
        "!mv /content/mirrorGAN/config.py /content/MirrorGAN/cfg/\n",
        "!mv /content/mirrorGAN/train_bird.yml /content/MirrorGAN/cfg/\n",
        "!mv /content/mirrorGAN/datasets.py /content/MirrorGAN/\n",
        "!mv /content/mirrorGAN/model.py /content/MirrorGAN/\n",
        "!mv /content/mirrorGAN/trainer.py /content/MirrorGAN/\n",
        "!mv /content/mirrorGAN/attn_captions.pickle /content/data/birds/"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'mirrorGAN'...\n",
            "remote: Enumerating objects: 49, done.\u001b[K\n",
            "remote: Counting objects:   2% (1/49)\u001b[K\rremote: Counting objects:   4% (2/49)\u001b[K\rremote: Counting objects:   6% (3/49)\u001b[K\rremote: Counting objects:   8% (4/49)\u001b[K\rremote: Counting objects:  10% (5/49)\u001b[K\rremote: Counting objects:  12% (6/49)\u001b[K\rremote: Counting objects:  14% (7/49)\u001b[K\rremote: Counting objects:  16% (8/49)\u001b[K\rremote: Counting objects:  18% (9/49)\u001b[K\rremote: Counting objects:  20% (10/49)\u001b[K\rremote: Counting objects:  22% (11/49)\u001b[K\rremote: Counting objects:  24% (12/49)\u001b[K\rremote: Counting objects:  26% (13/49)\u001b[K\rremote: Counting objects:  28% (14/49)\u001b[K\rremote: Counting objects:  30% (15/49)\u001b[K\rremote: Counting objects:  32% (16/49)\u001b[K\rremote: Counting objects:  34% (17/49)\u001b[K\rremote: Counting objects:  36% (18/49)\u001b[K\rremote: Counting objects:  38% (19/49)\u001b[K\rremote: Counting objects:  40% (20/49)\u001b[K\rremote: Counting objects:  42% (21/49)\u001b[K\rremote: Counting objects:  44% (22/49)\u001b[K\rremote: Counting objects:  46% (23/49)\u001b[K\rremote: Counting objects:  48% (24/49)\u001b[K\rremote: Counting objects:  51% (25/49)\u001b[K\rremote: Counting objects:  53% (26/49)\u001b[K\rremote: Counting objects:  55% (27/49)\u001b[K\rremote: Counting objects:  57% (28/49)\u001b[K\rremote: Counting objects:  59% (29/49)\u001b[K\rremote: Counting objects:  61% (30/49)\u001b[K\rremote: Counting objects:  63% (31/49)\u001b[K\rremote: Counting objects:  65% (32/49)\u001b[K\rremote: Counting objects:  67% (33/49)\u001b[K\rremote: Counting objects:  69% (34/49)\u001b[K\rremote: Counting objects:  71% (35/49)\u001b[K\rremote: Counting objects:  73% (36/49)\u001b[K\rremote: Counting objects:  75% (37/49)\u001b[K\rremote: Counting objects:  77% (38/49)\u001b[K\rremote: Counting objects:  79% (39/49)\u001b[K\rremote: Counting objects:  81% (40/49)\u001b[K\rremote: Counting objects:  83% (41/49)\u001b[K\rremote: Counting objects:  85% (42/49)\u001b[K\rremote: Counting objects:  87% (43/49)\u001b[K\rremote: Counting objects:  89% (44/49)\u001b[K\rremote: Counting objects:  91% (45/49)\u001b[K\rremote: Counting objects:  93% (46/49)\u001b[K\rremote: Counting objects:  95% (47/49)\u001b[K\rremote: Counting objects:  97% (48/49)\u001b[K\rremote: Counting objects: 100% (49/49)\u001b[K\rremote: Counting objects: 100% (49/49), done.\u001b[K\n",
            "remote: Compressing objects:   2% (1/34)\u001b[K\rremote: Compressing objects:   5% (2/34)\u001b[K\rremote: Compressing objects:   8% (3/34)\u001b[K\rremote: Compressing objects:  11% (4/34)\u001b[K\rremote: Compressing objects:  14% (5/34)\u001b[K\rremote: Compressing objects:  17% (6/34)\u001b[K\rremote: Compressing objects:  20% (7/34)\u001b[K\rremote: Compressing objects:  23% (8/34)\u001b[K\rremote: Compressing objects:  26% (9/34)\u001b[K\rremote: Compressing objects:  29% (10/34)\u001b[K\rremote: Compressing objects:  32% (11/34)\u001b[K\rremote: Compressing objects:  35% (12/34)\u001b[K\rremote: Compressing objects:  38% (13/34)\u001b[K\rremote: Compressing objects:  41% (14/34)\u001b[K\rremote: Compressing objects:  44% (15/34)\u001b[K\rremote: Compressing objects:  47% (16/34)\u001b[K\rremote: Compressing objects:  50% (17/34)\u001b[K\rremote: Compressing objects:  52% (18/34)\u001b[K\rremote: Compressing objects:  55% (19/34)\u001b[K\rremote: Compressing objects:  58% (20/34)\u001b[K\rremote: Compressing objects:  61% (21/34)\u001b[K\rremote: Compressing objects:  64% (22/34)\u001b[K\rremote: Compressing objects:  67% (23/34)\u001b[K\rremote: Compressing objects:  70% (24/34)\u001b[K\rremote: Compressing objects:  73% (25/34)\u001b[K\rremote: Compressing objects:  76% (26/34)\u001b[K\rremote: Compressing objects:  79% (27/34)\u001b[K\rremote: Compressing objects:  82% (28/34)\u001b[K\rremote: Compressing objects:  85% (29/34)\u001b[K\rremote: Compressing objects:  88% (30/34)\u001b[K\rremote: Compressing objects:  91% (31/34)\u001b[K\rremote: Compressing objects:  94% (32/34)\u001b[K\rremote: Compressing objects:  97% (33/34)\u001b[K\rremote: Compressing objects: 100% (34/34)\u001b[K\rremote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "Unpacking objects:   2% (1/49)   \rUnpacking objects:   4% (2/49)   \rUnpacking objects:   6% (3/49)   \rUnpacking objects:   8% (4/49)   \rUnpacking objects:  10% (5/49)   \rUnpacking objects:  12% (6/49)   \rUnpacking objects:  14% (7/49)   \rUnpacking objects:  16% (8/49)   \rUnpacking objects:  18% (9/49)   \rUnpacking objects:  20% (10/49)   \rUnpacking objects:  22% (11/49)   \rUnpacking objects:  24% (12/49)   \rUnpacking objects:  26% (13/49)   \rUnpacking objects:  28% (14/49)   \rUnpacking objects:  30% (15/49)   \rUnpacking objects:  32% (16/49)   \rUnpacking objects:  34% (17/49)   \rUnpacking objects:  36% (18/49)   \rUnpacking objects:  38% (19/49)   \rUnpacking objects:  40% (20/49)   \rUnpacking objects:  42% (21/49)   \rUnpacking objects:  44% (22/49)   \rUnpacking objects:  46% (23/49)   \rUnpacking objects:  48% (24/49)   \rremote: Total 49 (delta 19), reused 38 (delta 11), pack-reused 0\u001b[K\n",
            "Unpacking objects:  51% (25/49)   \rUnpacking objects:  53% (26/49)   \rUnpacking objects:  55% (27/49)   \rUnpacking objects:  57% (28/49)   \rUnpacking objects:  59% (29/49)   \rUnpacking objects:  61% (30/49)   \rUnpacking objects:  63% (31/49)   \rUnpacking objects:  65% (32/49)   \rUnpacking objects:  67% (33/49)   \rUnpacking objects:  69% (34/49)   \rUnpacking objects:  71% (35/49)   \rUnpacking objects:  73% (36/49)   \rUnpacking objects:  75% (37/49)   \rUnpacking objects:  77% (38/49)   \rUnpacking objects:  79% (39/49)   \rUnpacking objects:  81% (40/49)   \rUnpacking objects:  83% (41/49)   \rUnpacking objects:  85% (42/49)   \rUnpacking objects:  87% (43/49)   \rUnpacking objects:  89% (44/49)   \rUnpacking objects:  91% (45/49)   \rUnpacking objects:  93% (46/49)   \rUnpacking objects:  95% (47/49)   \rUnpacking objects:  97% (48/49)   \rUnpacking objects: 100% (49/49)   \rUnpacking objects: 100% (49/49), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8mG_vcAqTKr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7ac28864-4381-425d-b241-0d2b5520fea2"
      },
      "source": [
        "os.chdir('/content/MirrorGAN') \n",
        "! ./do_train.sh"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using config:\n",
            "{'B_VALIDATION': False,\n",
            " 'CAP': {'caption_cnn_path': '../data/STREAM/cnn_encoder.ckpt',\n",
            "         'caption_rnn_path': '../data/STREAM/rnn_decoder.ckpt',\n",
            "         'embed_size': 256,\n",
            "         'hidden_size': 256,\n",
            "         'learning_rate': 0.001,\n",
            "         'num_layers': 1},\n",
            " 'CONFIG_NAME': 'MirrorGAN',\n",
            " 'CUDA': True,\n",
            " 'DATASET_NAME': 'birds',\n",
            " 'DATA_DIR': '../data/birds',\n",
            " 'GAN': {'B_ATTENTION': True,\n",
            "         'B_DCGAN': False,\n",
            "         'CONDITION_DIM': 100,\n",
            "         'DF_DIM': 64,\n",
            "         'GF_DIM': 32,\n",
            "         'R_NUM': 2,\n",
            "         'Z_DIM': 100},\n",
            " 'GPU_ID': 0,\n",
            " 'OUTPUT_PATH': '/data/qtt/MirrorGAN/',\n",
            " 'RNN_TYPE': 'LSTM',\n",
            " 'TEXT': {'CAPTIONS_PER_IMAGE': 10, 'EMBEDDING_DIM': 256, 'WORDS_NUM': 18},\n",
            " 'TRAIN': {'BATCH_SIZE': 12,\n",
            "           'B_NET_D': True,\n",
            "           'DISCRIMINATOR_LR': 0.0002,\n",
            "           'ENCODER_LR': 0.0002,\n",
            "           'FLAG': True,\n",
            "           'GENERATOR_LR': 0.0002,\n",
            "           'MAX_EPOCH': 650,\n",
            "           'NET_E': '../data/STEM/text_encoder.pth',\n",
            "           'NET_G': '',\n",
            "           'RNN_GRAD_CLIP': 0.25,\n",
            "           'SMOOTH': {'GAMMA1': 4.0,\n",
            "                      'GAMMA2': 5.0,\n",
            "                      'GAMMA3': 10.0,\n",
            "                      'LAMBDA': 0.0,\n",
            "                      'LAMBDA1': 10.0},\n",
            "           'SNAPSHOT_INTERVAL': 50},\n",
            " 'TREE': {'BASE_SIZE': 64, 'BRANCH_NUM': 3},\n",
            " 'WORKERS': 4}\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:211: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
            "  \"please use transforms.Resize instead.\")\n",
            "Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg\n",
            "Calling Load text data\n",
            "Load filenames from: ../data/birds/train/filenames.pickle (8855)\n",
            "Load filenames from: ../data/birds/test/filenames.pickle (2933)\n",
            "--------------------Load Text Data--------------------------------------\n",
            "FilePath:  ../data/birds/attn_captions.pickle Does Exist :  False\n",
            "Load from:  ../data/birds/attn_captions.pickle\n",
            "Calling Load Class ID\n",
            "Finished Load Class ID \n",
            "Number of Example: 8855\n",
            "Load pretrained model from  https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\n",
            "Load image encoder from: ../data/STEM/image_encoder.pth\n",
            "self.n_steps: 18\n",
            "self.ntoken: 5450\n",
            "self.ninput: 300\n",
            "self.drop_prob: 0.5\n",
            "self.nlayers: 1\n",
            "self.bidirectional: True\n",
            "self.rnn_type: LSTM\n",
            "self.nhidden: 128\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "Load text encoder from: ../data/STEM/text_encoder.pth\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 135, in <module>\n",
            "    algo.train()\n",
            "  File \"/content/MirrorGAN/trainer.py\", line 233, in train\n",
            "    text_encoder, image_encoder, caption_cnn, caption_rnn, netG, netsD, start_epoch = self.build_models()\n",
            "  File \"/content/MirrorGAN/trainer.py\", line 71, in build_models\n",
            "    caption_cnn.load_state_dict(torch.load(cfg.CAP.caption_cnn_path, map_location=lambda storage, loc: storage))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/serialization.py\", line 584, in load\n",
            "    with _open_file_like(f, 'rb') as opened_file:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/serialization.py\", line 234, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/serialization.py\", line 215, in __init__\n",
            "    super(_open_file, self).__init__(open(name, mode))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '../data/STREAM/cnn_encoder.ckpt'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdBBXnkQqUQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}